\Sexpr{set_parent('paper.Rnw')}
\section{Application: Multi-objective optimization}
\label{sec:app2}


"Note also that it is very hard to define a priori which model
size would be considered “too large” to be analyzed by a user.
Hence, instead of specifying the maximum size of a classification
model as a parameter of a classification algorithm, we prefer a
more principled approach to cope with the accuracy-
comprehensibility trade-off, such as a multi-objective approach
based on Pareto dominance or lexicographic optimization""
\citep{freitas2014comprehensible}




<<mo-data>>=
configureMlr(show.info = FALSE)

devtools::load_all()
set.seed(42)

TASK_TYPE = "regr"

tasks = listOMLTasks()
if(TASK_TYPE == "regr") {
  tasks = tasks[grepl("Supervised Regression", tasks$task.type), ]
} else {
  tasks = tasks[grepl("Supervised Classification", tasks$task.type), ]
  tasks = tasks[tasks$number.of.classes  == 2, ]
}
tasks = tasks[tasks$number.of.instances.with.missing.values == 0, ]
tasks = tasks[tasks$number.of.symbolic.features > 0, ]
tasks = tasks[tasks$number.of.features < 150, ]
tasks = tasks[tasks$number.of.features > 4, ]
tasks = tasks[tasks$number.of.instances < 10000, ]
tasks = tasks[tasks$number.of.instances > 200, ]
tasks = tasks[!is.na(tasks$task.id), ]

i = 8


task = getOMLTask(task.id = tasks$task.id[i])
task = convertOMLTaskToMlr(task)
task = task$mlr.task
task.dat = getTaskData(task)
summary(task.dat)
print(dim(task.dat))
# devtools::load_all()
# set.seed(42)
# wine = read.csv("./data/winequalityN.csv")
# wine = na.omit(wine)
#
# WINE_SAMPLE = sample(1:nrow(wine), size = 300)
# wine = wine[WINE_SAMPLE, ]
#
# task = makeRegrTask(data = wine, target = "quality")
# task.dat = getTaskData(task)
# summary(task.dat)
# print(dim(task.dat))
@


<<mo-run, dependson="mo-data">>=
base.learners.classif = list(
  makeLearner("classif.ksvm", predict.type = "prob"),
  makeLearner("classif.rpart", predict.type = "prob"),
  makeLearner("classif.gamboost", predict.type = "prob"),
  makeLearner("classif.kknn", predict.type = "prob"),
  makeLearner("classif.naiveBayes", predict.type = "prob")
)

base.learners.regr = list(
  makeLearner("regr.ksvm"),
  makeLearner("regr.xgboost.mod"),
  makeLearner("regr.rpart"),
  makeLearner("regr.gamboost")
)

lrn.regr = makeModelMultiplexer(base.learners.regr)
lrn.classif = makeModelMultiplexer(base.learners.classif)

ps.regr = makeModelMultiplexerParamSet(lrn.regr,
  makeNumericParam("C", lower = 0, upper = 100),
  makeIntegerParam ("max_depth" , lower = 1, upper = 6, requires = quote(booster == "gbtree")),
  makeIntegerParam ("maxdepth" , lower = 1, upper = 10),
  makeDiscreteParam("booster", values = c("gbtree", "gblinear")),
  makeNumericParam("alpha", lower = 0, upper = 100, requires = quote(booster == "gblinear")),
  makeIntegerParam("nrounds", lower = 1, upper = 1000),
  makeIntegerParam("mstop", lower = 1, upper = 1000)
)

ps.classif = makeModelMultiplexerParamSet(lrn.classif,
  makeNumericParam("C", lower = 0, upper = 100),
  makeIntegerParam ("maxdepth" , lower = 1, upper = 10),
  makeIntegerParam("mstop", lower = 1, upper = 1000),
  makeIntegerParam("k", lower = 1, upper = 10),
  makeNumericParam("laplace", lower = 0, upper = 1)
)

rin = makeResampleInstance(cv2 , task)

if(TASK_TYPE == "classif") {
  lrn = lrn.classif
  loss = auc
  ps = ps.classif
} else {
  lrn = lrn.regr
  loss = mae
  ps = ps.regr
}


sample.size = min(nrow(task.dat), 300)
sample.size = nrow(task.dat)
subset_index = sample(1:nrow(task.dat), size = sample.size)

fn = function(x){
  # removes unused params
  x = x[!is.na(x)]
  lrn = setHyperPars(lrn, par.vals = x)
  perf = resample(learner = lrn, show.info = FALSE,
    task = task , resampling = rin ,
    measures = list(loss))$aggr
  mod = train(lrn, task)
  pred = Predictor$new(mod, task.dat[subset_index,], y = task$task.desc$target)
  imeasure = FunComplexity$new(pred)
  c(round(perf, 2),
    round(imeasure$c_wmean, 2),
    round(1 - imeasure$r2, 2),
    imeasure$n_features)
}

obj.fun = makeMultiObjectiveFunction(fn = fn, par.set = ps, n.objectives = 4, has.simple.signature = FALSE)

ctrl = makeMBOControl(n.objectives = 4L)
ctrl = setMBOControlInfill(ctrl, crit = crit.cb)
ctrl = setMBOControlMultiObj(ctrl, method = "parego")

mbo.lrn = makeLearner("regr.randomForest", predict.type = "se", ntree = 200)
mbo.lrn = makeImputeWrapper(mbo.lrn, classes = list(numeric = imputeMax(2), factor = imputeConstant("__miss__")))

design = generateDesign(n = 20L, par.set = ps, fun = lhs::randomLHS)

mbo.iml = mbo(fun = obj.fun, design = design, learner = mbo.lrn, control = ctrl)
pareto.set = rbindlist(lapply(mbo.iml$pareto.set, data.frame))
best.models = cbind(round(mbo.iml$pareto.front, 2), pareto.set)
@

TODO: Show visualization of results
TODO: Show FunComplexity of model with best performance
TODO: Pick one other interesting model and show FunComplexity


<<mo-results, dependson="mo-setup", eval=FALSE>>=
is_duplicated = duplicated(best.models[,1:5])
best.models = best.models[!is_duplicated,]
best.models %>%
  arrange(y_1)


best.models %>%
  arrange(y_2)


best.models$overall_complexity = best.models$y_2 * (1 + best.models$y_3)
best.models$interpretability  = 1 - (best.models$overall_complexity / max(best.models$overall_complexity))

y = task.dat[task$task.desc$target][[1]]
mae_0 = measureMAE(truth = y, response = mean(y))
mae_0 = 0.5
ggplot(best.models, aes(y = (mae_0 - y_1)/( mae_0 - min(y_1)),
  x = interpretability)) + geom_point() +
  geom_label(aes(label = selected.learner, fill = y_3)) +
  scale_x_continuous("Interpretability") +
  scale_y_continuous("Accuracy")


ggplot(best.models, aes(y = (mae_0 - y_1)/( mae_0 - min(y_1)),
  x = 1 - y_3)) + geom_point() +
  geom_label(aes(label = selected.learner)) +
  scale_x_continuous("Interpretability") +
  scale_y_continuous("Accuracy")




ggplot(best.models, aes(y = (mae_0 - y_1)/( mae_0 - min(y_1)),
  x = (max(y_2) - y_2) / max(y_2) * (1 - y_3))) + geom_point() +
  geom_label(aes(label = selected.learner)) +
  scale_x_continuous("Interpretability") +
  scale_y_continuous("Accuracy")



# TODO: Also keep original measures
# Scale measures to [0,1]
best.models$y_1 = 1 - (best.models$y_1 - min(best.models$y_1)) / (max(best.models$y_1) - min(best.models$y_1))
best.models$y_2 = (best.models$y_2 - min(best.models$y_2)) / (max(best.models$y_2) - min(best.models$y_1))
# y_3 already scaled between 0 and 1
best.models$y_3 = (best.models$y_3 - min(best.models$y_3)) / (max(best.models$y_3) - min(best.models$y_3))
best.models$y_4 = best.models$y_4 / sum(task$task.desc$n.feat)

measure_names = c("Performance", "Complexity", "Interaction", "#Features")
colnames(best.models)[1:4] = measure_names
plot.dat = melt(best.models, measure.vars = measure_names)

param_cols = setdiff(colnames(best.models), c(measure_names, "selected.learner"))


plot.dat$lrn_descr = apply(plot.dat, 1, function(row) {
  lrn_name = row['selected.learner']
  params = row[param_cols]
  params = params[!is.na(params)]
  names(params) = gsub(sprintf("%s.", lrn_name), "", names(params), fixed = TRUE)
  param_string = sprintf("%s:%s", names(params), params)
  param_string = paste(param_string, collapse = ",")
  sprintf("%s (%s)", lrn_name, param_string)
})

ggplot(plot.dat) +
  geom_col(aes(x = variable, y = value, color = selected.learner)) +
  facet_wrap("lrn_descr") +
  coord_flip()


max.plot.dat = plot.dat
max.plot.dat$value = 1

ggplot(mapping = aes(x = variable, y = lrn_descr, size = value)) +
  geom_point(data = max.plot.dat, shape = 1) +
  geom_point(data = plot.dat) +
  scale_size_continuous(range = c(0,10), guide = "none") +
  scale_y_discrete("")

## Extract parameters and refit best solutions

pareto_index = 1

pp = mbo.iml$pareto.set[[pareto_index]]
pp = pp[!is.na(pp)]
lrn = setHyperPars(lrn, par.vals = pp)
mod = train(lrn, task)
pred = Predictor$new(mod, task.dat)
fc = FunComplexity$new(pred)

plot(fc)



@




















TODO:

- Re-Create the interpretability vs accuracy figure
To get interpretability to one dimension:
We have 100 percent variance of y.
x percent is explained by interations
1 - x percent is explained by 1st order model.
first order complexity is C.
we claim that the average complexity of higher-order is the same as 1st order and simply project the functional complexity to the rest:
$overall.complexity = c  + c \cdot x  = c times (1 + x)$
and to flip direction and scale to 0 and 1 (only when multiple models are tested):
$interpretability = 1 - overall_c / max(overall_c)$

theoretically maximal complexity:
$max.components \cdot n_features \cdot (1 + c)$
where max.components is the maximal complexity a feature can get based on user input and n.features the number of features.

Mathematically writing down objectives

Short mbo summary and setup.
 Tune across many learners (xgboost, svm, lm, rpart, ...)
Many datasets
Show Pareto Front for some datasets.

Aggregated results per learner (maybe do mbo per learner) and recreate accuracy / interpretability figures





