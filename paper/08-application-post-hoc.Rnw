\Sexpr{set_parent('paper.Rnw')}
\section{Improving post-hoc interpretation}
\label{sec:post-hoc}

We demonstrate that minimizing the number of features (NF), the interaction strength (IAS) and the main effect complexity (AMEC) improves readability, reliability and summarizability of post-hoc interpretation methods like partial dependence plots, feature importance, interaction effects, local surrogate models, etc..

\subsubsection{The less features, the less verbose the interpretations.}
Minimizing the number of features improves the manageability of post-hoc analysis results.
The computational time and output size of most interpretation methods scales with $O(\text{NF})$, like feature effect plots \citep{apley2016visualizing,friedman2001greedy} or feature importance \citep{fisher2018all,casalicchio2018visualizing}.
If 100 features  were used, 100 feature effect plots have to be looked at to make a sanity check of what the mdoel does.
Interpretation methods that analyze the interactions between features, e.g. when analyzing 2-way interactions, scale with $O(\text{NF}^2)$ and if you were to do a full functional decomposition be it either through the approach by Hooker \citep{hooker2007generalized} or Apley \citep{apley2016visualizing}, the computation time and output size scales with $O(\text{NF}!)$.

\subsubsection{The less features, the less severe the curse of dimensionality.}
Some interpretation methods like SHAP \citep{lundberg2017unified} or LIME \citep{ribeiro2016should} create sparse interpretations by selecting relevant features.
The more high-dimensional the feature features space (high NF), the more difficult it can become to find the most relevant features and the fidelity of an explanation suffers the higher the divergence between the number of features used by the black box model and the number used by the explanation.
SHAP and LIME also rely on distance measures between instances, which is also affected by the curse of dimensionality and with increasing number of features distance loose their usefulness (lower signal to noise ratio).

\subsubsection{The less interactions, the more reliable feature effect plots.}
Feature effect plots, like partial dependence plots and accumulated local effect plots visualize the marginal relationship between a feature and the prediction.
The estimated effects are averages over the instances and the effects of features per instance can vary greatly, even take on a different direction when the model incorporates interactions
For example a feature might show a positive effect on the prediction, but for some instances the effect might be negative.


<<prepare-pdp-unreliable, out.height="3cm", cache=FALSE>>=
set.seed(123)
n = 500

cnames = c("x1", "x2", "x3", "x4", "y")

dat = mlbench::mlbench.friedman2(n, sd = 0.3)
datx = data.frame(cbind(dat$x, "y" = dat$y))
names(datx) = cnames
task = makeRegrTask(data  = datx, target = "y")

n.test = 100
dat2 = mlbench::mlbench.friedman2(n.test, sd = 0.3)
datx2 = data.frame(cbind(dat2$x, "y" = dat2$y))
names(datx2) = cnames
task2 = makeRegrTask(data  = datx2, target = "y")


y_limit = c(-200, 1200)
grid.size = 100
feature = "x2"
@

In the following simulated example we trained three models with different capabilities of modeling interactions between features: a linear regression model, a random forest and a k-nearest-neighbors model.
We simulated 500 data points with 4 features and a continuous target to be predicted \citep{friedman1991multivariate}.
The features are uniformly distributed in the following intervals: $0\leq x_1 \leq 100$, $ 40\pi \leq x_2 \leq 560 \pi$, $ 0 \leq x_3 \leq 1$, $ 1 \leq x_4 \leq 11$.
The regression target was simulated as:

$$y = (x_1^2 + (x_2 \cdot x_3 - (1/(x_2 \cdot x_4)))^2)^{0.5} + e$$
where $ e \sim N(0,125)$.

<<pdp-unreliable, fig.cap="The higher the interaction strength in a model (IAS increasing from left to right), the more less accurate the main effect plot for feature x2 becomes (here, partial dependence plots), as the feature effect vary more between instances as visualized with individual conditional expectation curves.", fig.height=4.5, fig.width=12, fig.align="center", out.height="4.5cm", out.width="12cm">>=
lrn = makeLearner("regr.lm")
mod.gamboost = train(lrn, task)
pred = Predictor$new(mod.gamboost, datx2, class = 1)

ylim = c(-10, 1300)
fc = FunComplexity$new(pred, grid.size = grid.size)
r2_gamboost = 1 - fc$r2
fe = FeatureEffects$new(pred, method = "pdp+ice", center.at = 0)
p_gamboost = plot(fe$effects[[feature]], ylim = y_limit) +
	geom_label(x = 700, y = 1000, label = sprintf("IAS = %.2f", r2_gamboost), size = 10) + 
  ggtitle("Linear Model") + 
  scale_y_continuous("Prediction (centered at x=0)", limits = ylim)


lrn = makeLearner("regr.randomForest")
mod.ranger = train(lrn, task)
pred = Predictor$new(mod.ranger, datx2)
fc = FunComplexity$new(pred, grid.size = grid.size)
r2_ksvm = 1- fc$r2
fe = FeatureEffects$new(pred, method = "pdp+ice", center.at = 0)
p_ksvm = plot(fe$effects[[feature]], ylim = y_limit) +
	geom_label(x = 700, y = 1000, label = sprintf("IAS = %.2f", r2_ksvm), size = 10) + 
  ggtitle("Random Forest") + 
  scale_y_continuous("", limits = ylim)


lrn = makeLearner("regr.kknn", k = 3)
mod.kknn = train(lrn, task)
pred = Predictor$new(mod.kknn, datx2, class = 1)
fc = FunComplexity$new(pred, grid.size = grid.size)
r2_kknn = 1- fc$r2
fe = FeatureEffects$new(pred, method = "pdp+ice", center.at = 0)
p_kknn = plot(fe$effects[[feature]], ylim = y_limit) +
	geom_label(x = 700, y = 1000, label = sprintf("IAS = %.2f", r2_kknn), size = 10) + 
  ggtitle("knn (k=3)") + 
  scale_y_continuous("", limits = ylim)

mae.gamboost = measureMAE(datx2$y, getPredictionResponse(predict(mod.gamboost, task2)))
mae.ranger = measureMAE(datx2$y, getPredictionResponse(predict(mod.ranger, task2)))
mae.kknn = measureMAE(datx2$y, getPredictionResponse(predict(mod.kknn, task2)))

grid.arrange(p_gamboost, p_ksvm, p_kknn, nrow = 1)
@

Figure \ref{fig:pdp-unreliable} shows an increasing interaction strength depending on the model used.
This means that we prefer models with less interactions when using feature effect plots.



\subsubsection{The less complex the main effects, the better summarizable.}
In linear models, the relationship between a feature and the predicted outcome can be expressed with a single number: the regression coefficient or weight.
Summarizing feature effects of non-linear models (e.g. logistic regression, neural networks) with a single number (average marginal effect) can be misleading, since effect directions can cancel each other out.
Our proposed MEC measure quantifies how many numbers we would need to describe a main effect up to a certain approximation error.
Minimizing MEC means preferring models with main effects that can be described with less numbers.
As a by-product of AMEC, we get for each feature a proposal how to optimally bin the feature into intervals with similar effect direction and strength.






