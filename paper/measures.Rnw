\Sexpr{set_parent('paper.Rnw')}
\section{Functional complexity}
\label{sec:measures}

% =============================================================================
% General idea in words
% =============================================================================
We decompose the prediction function into a constant term plus main effects (estimated with Accumulated Local Effects) plus an interaction rest and measure the number of features that were used (NF), the interaction strength (IAS) and the average main effect complexity (AMEC).
These measures quantify the complexity of a machine learning model from an external view onto the shape of the prediction function and ignores the internal model structure.


% =============================================================================
% Decomposition and Simplification
% =============================================================================
We arrange the terms of Equation \ref{eqn:decomp} and replace the main effects with their ALE definition:
\begin{eqnarray} f(x) % = &\overbrace{f_0}^\text{Intercept} + \overbrace{\sum_{j=1}^p f_j(x_j)}^\text{1st order effects} + \overbrace{\sum_{S \subseteq \{1,\ldots,p\},|S| \geq 2} f_{S}(x_S)}^{\text{Higher order effects}} \\
=&\underbrace{f_0 + \sum_{j=1}^p \overbrace{\falej(x_j)}^\text{AMEC: How complex?} + \overbrace{IA(x)}^{\text{IA: How much interaction?}}}_{\text{NF: How many feature used?}}
\end{eqnarray}i
The constant term is estimated with the mean of the model prediction $f_0 = \frac{1}{n}\sum_{i=1}^n \hat{f}(\xi)$ and the main effects with Accumulated Local Effects.
The remaining part with the interactions of the decomposition does not have to be computed for our proposed measures.
This arrangement of components emphasizes the view of the model as the mixture of an additive main effect model and interactions between the features.
The main effects can be arbitrarily complex one-dimensional functions which we can visualized.
In isolation from the interactions, the main effect model constitutes a prediction function and we can analyze how well it already approximates $\fh$, which is the idea behind the interaction measure IAS.
Depending on the underlying model class and the true relationships in the data, the individual main effect curves can be of different complexity.
The average main effect complexity (AMEC) tries to capture how many parameters we need to describe the main effects on average.


% =============================================================================
% Replace components with ALE
% =============================================================================
We compute the main effects using accumulated local effects proposed by \cite{apley2016visualizing}.
The ALE main effect of a feature $x_j, j \in \{1,\ldots,p\}$ for a prediction function $\fh$ is defined as 
\begin{eqnarray}
f_{j,ALE}(x_j) = \int_{z_{0,j}}^{x_j} \mathbb{E}\left[\frac{\delta \fh(X_1,\ldots,X_p)}{\delta X_j}|X_j = z_j\right]dz_j-c_j
\end{eqnarray}
Here, $X_j$ refers to the j-the feature as a random variable and $z_{0,j}$ is a lower bound of $X_j$ (usually estimated with the minimal observed value) and the expectation $\mathbb{E}$ is computed marginal on the distribution of all features conditioned on the value for $x_j$.
The constant $c_1$ is chosen so that the mean of $f_{j,ALE}(x_j)$ with respect to the marginal distribution of $X_j$ is zero.
While the definition of ALE main effects is based on the gradient with respect to the features, they can also be estimated for non-differentiable prediction functions, since an estimation approach based on finite differences is suggested.
For the actual estimation we refer to \citep{apley2016visualizing}.
% Categorical features
%Categorical features require an ordering of the categories so that accumulated local effects can be estimated.
%Any ordering of the categories will yield a valid ALE, but the interpretation differs, because category effects are interpreted in terms of changes to the neighbouring categories.


% =============================================================================
% Why minimize proposed measures?
% =============================================================================
%When the three measures are minimized, the following improvements of interpretability will be reached.
%Minimizing the number of features to be used directly improves the sparsity of the model.
%The less features are used, the less plots have to be looked at and the less numbers are needed to describe e.g. the feature importance and so on.
%Minimizing the strength of interactions increases how much of the prediction variance the main effects explain.
%If the interaction measure is zero, the ALE plots will explain all of the models variance.
%Minimizing the complexity of the first order effects ensures that we need less parameters to (approximately) describe the main effects.
%A complexity of 1 means that we only need a single number to describe the relationship.




% -----------------------------------------------------------------------------
% Material
% -----------------------------------------------------------------------------

% We do the following approximation:
%
% \begin{eqnarray*}
% f(x)  =& \overbrace{f_0}^\text{Intercept} + \overbrace{\sum_{j=1}^p f_j(x_j)}^\text{1st order effects} + \overbrace{\sum_{j\neq k}^p f_{jk}(x_{jk})}^\text{2nd order effects} + \ldots + \overbrace{f_{1,\ldots,p}(x_{1,\ldots,p})}^\text{p-th order effect}\\
%      =& f_0 + \sum_{j=1}^{p} f_{j}(x_j) + \sum_{S \subseteq \{1,\ldots,p\}} f_{S}(x_S)\\
%      =& \bar{f}(x) + \sum_{j=1}^{p} f_{j,ALE}(x_j)  + IA(x) \\
%      =& \bar{f}(x) + \sum_{j=1}^{p} (\tilde{f}_{j,ALE}(x_j) + \epsilon_{j}(x_j)) + IA(x) \\
% \end{eqnarray*}
%
% $\tilde{f}_{j,ALE}(x_j) $ is the approximation of the j-th main effect.\\
% $\epsilon_{j}(x_j)$ is the approximiation error $f_{j,ALE}(x_j) - \tilde{f}_{j,ALE}(x_j)$\\
% $IA(x)$ the interaction terms.\\


% \citep{murdoch2019interpretable} defines the following desiderata for an interpretability measure:
% Accuracy
% \begin{itemize}
% \item Accuracy (of interpretation method), which matches that we look at R squared. Predictive accuracy is measured as usual. Descriptive accuracy is measured with novel measures
% \item Relevancy: Show only relevant information. With our measures we can decide which plots to show. Remove when effect is zero. Also we can measure variance of each of the 1st order components and only show the most relevant ones.
% \item Sparsity: Directly optimized with our measures
% \item Simulatability: Can human internally simulate and reason about
% \item Modularity: Can model parts be interpreted independently? Interaction measure allows us to determine how independently we can analyze the individual features with their ALE plots
% \item They also say: "Moreover, it is unclear if any of the current interpretation forms can fully capture a modelâ€™s behaviour, or if a new format altogether is needed. How to close that gap, while producing outputs relevant to a particular audience/problem, is an open problem."
% \end{itemize}
%
% We claim that optimizing the two measures we will propose will improve those desiderata:
% Decreasing interactions will improve the accuracy of the view of ALE first order plots.
% modularity is achieved by doing a decomposition.
% With interaction measure you can see how much the first order ALE plots of the variance already explain.


