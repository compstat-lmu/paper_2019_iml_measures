\Sexpr{set_parent('paper.Rnw')}
\section{Functional complexity}
\label{sec:measures}

% =============================================================================
% General idea in words
% =============================================================================
We decompose the prediction function into a constant term plus main effects (estimated with ALE) plus a rest containing interactions, then we measure the number of features(NF) that were used (see Section~\ref{sec:nfeatures}), the interaction strength (IA) (see Section~\ref{sec:interaction} and the average main effect complexity (MEC) (see Section \ref{sec:curve}.
These measures quantify the complexity of a machine learning model from an external view onto the shape of the prediction function and ignores the actual representation of the model (e.g. tree structure).


% =============================================================================
% Decomposition and Simplification
% =============================================================================
Based on Equation~\ref{eqn:decomp}, we estimate the main effects by ALE and summarize the interaction in a rest term $IA(x)$:
\begin{eqnarray} f(x) % = &\overbrace{f_0}^\text{Intercept} + \overbrace{\sum_{j=1}^p f_j(x_j)}^\text{1st order effects} + \overbrace{\sum_{S \subseteq \{1,\ldots,p\},|S| \geq 2} f_{S}(x_S)}^{\text{Higher order effects}} \\
=&\underbrace{f_0 + \sum_{j=1}^p \overbrace{\falej(x_j)}^\text{AMEC: How complex?} + \overbrace{IA(x)}^{\text{IA: Interaction strength?}}}_{\text{NF: How many features were used}}
\end{eqnarray}
The constant term is estimated with the mean of the model prediction $f_0 = \frac{1}{n}\sum_{i=1}^n \hat{f}(\xi)$.
This arrangement of components emphasizes the view of the model as the mixture of an additive main effect model and interactions between the features.
The main effects can be arbitrarily complex one-dimensional functions which we can visualize.
The idea behind the IA measure is to quantify how well the main effects approximate $\fh$ without the interactions.
In isolation from the interactions, the main effect model constitutes a prediction function and we can analyze how well it already approximates $\fh$, which is the idea behind the interaction measure IAS.
Depending on the underlying model class and the true relationships in the data, the individual main effect curves can be of different complexity.
The average main effect complexity (AMEC) tries to capture how many parameters we need to describe the main effects on average.


% =============================================================================
% Replace components with ALE
% =============================================================================
We compute the main effects using accumulated local effects proposed by \cite{apley2016visualizing}.

% =============================================================================
% Why minimize proposed measures?
% =============================================================================
%When the three measures are minimized, the following improvements of interpretability will be reached.
%Minimizing the number of features to be used directly improves the sparsity of the model.
%The less features are used, the less plots have to be looked at and the less numbers are needed to describe e.g. the feature importance and so on.
%Minimizing the strength of interactions increases how much of the prediction variance the main effects explain.
%If the interaction measure is zero, the ALE plots will explain all of the models variance.
%Minimizing the complexity of the first order effects ensures that we need less parameters to (approximately) describe the main effects.
%A complexity of 1 means that we only need a single number to describe the relationship.




% -----------------------------------------------------------------------------
% Material
% -----------------------------------------------------------------------------

% We do the following approximation:
%
% \begin{eqnarray*}
% f(x)  =& \overbrace{f_0}^\text{Intercept} + \overbrace{\sum_{j=1}^p f_j(x_j)}^\text{1st order effects} + \overbrace{\sum_{j\neq k}^p f_{jk}(x_{jk})}^\text{2nd order effects} + \ldots + \overbrace{f_{1,\ldots,p}(x_{1,\ldots,p})}^\text{p-th order effect}\\
%      =& f_0 + \sum_{j=1}^{p} f_{j}(x_j) + \sum_{S \subseteq \{1,\ldots,p\}} f_{S}(x_S)\\
%      =& \bar{f}(x) + \sum_{j=1}^{p} f_{j,ALE}(x_j)  + IA(x) \\
%      =& \bar{f}(x) + \sum_{j=1}^{p} (\tilde{f}_{j,ALE}(x_j) + \epsilon_{j}(x_j)) + IA(x) \\
% \end{eqnarray*}
%
% $\tilde{f}_{j,ALE}(x_j) $ is the approximation of the j-th main effect.\\
% $\epsilon_{j}(x_j)$ is the approximiation error $f_{j,ALE}(x_j) - \tilde{f}_{j,ALE}(x_j)$\\
% $IA(x)$ the interaction terms.\\


% \citep{murdoch2019interpretable} defines the following desiderata for an interpretability measure:
% Accuracy
% \begin{itemize}
% \item Accuracy (of interpretation method), which matches that we look at R squared. Predictive accuracy is measured as usual. Descriptive accuracy is measured with novel measures
% \item Relevancy: Show only relevant information. With our measures we can decide which plots to show. Remove when effect is zero. Also we can measure variance of each of the 1st order components and only show the most relevant ones.
% \item Sparsity: Directly optimized with our measures
% \item Simulatability: Can human internally simulate and reason about
% \item Modularity: Can model parts be interpreted independently? Interaction measure allows us to determine how independently we can analyze the individual features with their ALE plots
% \item They also say: "Moreover, it is unclear if any of the current interpretation forms can fully capture a modelâ€™s behaviour, or if a new format altogether is needed. How to close that gap, while producing outputs relevant to a particular audience/problem, is an open problem."
% \end{itemize}
%
% We claim that optimizing the two measures we will propose will improve those desiderata:
% Decreasing interactions will improve the accuracy of the view of ALE first order plots.
% modularity is achieved by doing a decomposition.
% With interaction measure you can see how much the first order ALE plots of the variance already explain.


