\Sexpr{set_parent('paper.Rnw')}
\section{Discussion}
\label{sec:discussion}

Measure favors sparse linear models without interaction terms.

Measure depend on the model but also on the type of decomposition we choose.
Therefore we blend representation of model components and model (difference explained by \citep{bibal2016interpretability}).
By choosing a decomposition with meaningful properties, like pseudo-independence of ALE, we get a meaningful approximation of the model components.


In the end, will a user also find models that minimize our notions of complexity more useful?
As \citep{rudin2018please} argues, this depends on the application and the audience.
We believe our measures are also useful for user surveys, because these measures can always be computed for the models that are being compared and correlated with user feedback to see what the tradeoff between performance and the different dimensions of complexity are in this particular case.

Problems:

- For tree based methods and other models with step curves, the ale fanova decomp never goes to perfectly zero, because it interpolates a little bit between the steps.
- When true marginal function is step function, then it adds to the SSE unecessarily
- Unclear how many intervals
- Weighted by data sensity (can be unintuitive when looking at plot) or all plot point same weight (probably very wrong). Solution: Make clear in ALE plot where most data is with rug or alpha.
- Short-comings: not tested with humans, but could be adapted and used with the same mult-crit framework.


There are many more use cases for the interpretability and complexity measures:
You can study how a tuning parameter affects interpretability.
Alternative measures:
\begin{itemize}
\item Monotonicity, which can also be asses through decomposition. Either only looking at main effects, or with ICE plots for all instances.
\item Average number of anchors?? Should be low for trees and lists, high for linear models.
\end{itemize}


Further research:


Implemented in iml package \citep{iml2018}


Better to tune complete pipeline with feature selection \citep{guyon2003introduction} to improve interpetability



% =============================================================================
% Funding
% =============================================================================
This work is funded by the Bavarian State Ministry of Science and the Arts in the framework of the Centre Digitisation.Bavaria (ZD.B)
