\Sexpr{set_parent('paper.Rnw')}
\section{Discussion}
\label{sec:discussion}


% =============================================================================
% Results summary
% =============================================================================
We proposed three model-agnostic measures of the functional complexity of a machine learning model: a heuristic for numbers of features used, the average main effect complexity, and the interaction strength.
All of those measures were motivated by the functional decomposition of the model prediction function and we demonstrated their usefulness in various examples.
As these measures are model-agnostic, one application of these measure is the comparison of interpretability across different model classes and even within a certain model class when different configurations / hyperparameter settings strongly affect the model structure (e.g. adding interactions into linear models or changing the kernel in a support vector machine).
The measures can be directly optimized in a multi-objective optimization setting.
It also allows to tune complete pipeline with feature selection \citep{guyon2003introduction} to improve interpetability

% =============================================================================
% Limitations
% =============================================================================
The measures as we proposed the come with a few limitations.
The measures favor sparse linear models without interaction terms.
In the end, will a user also find models that minimize our notions of complexity more useful?
We did not test whether optimizing those measures improves the interpretability of the models for humans, which ideally should be tested in a user-survey.
This was outside of the scope of our research.
These complexity measures can be directly used in research settings with user-surveys and correlated with user-reported outcomes and measure of how fast users where to grasp a model.
As \citep{rudin2018please} argues, the interpretability depends on the application and the audience and the preferred tradeoff between performance, sparsity, additivity and interactions might vary between different appication and audience.
We believe our measures are useful for user surveys, because these measures can always be computed for the models that are being compared and correlated with user feedback to see what the tradeoff between performance and the different dimensions of complexity are in this particular case.
Based on study by \citep{friedler2019assessing}, we can directly translate measures into human interpretability (given the limitations of their study).
The complexity, interactions and number of features can be translated into number of operations (at least approximately), even though it's not from true model interna, but from approximation outside the model.
Between the model and a human is always the representation of the model, which our measures do not evaluate.
A naturally ocurring representation from our approach is the ALE visualization of the main effects, but this is not necessarily the best representation for an end user.

% =============================================================================
% Areas to improve
% =============================================================================
The proposed measure for the main effect complexity could be improved by considering shapes different from linear segments.
For example quadratic components or seasonal components, which make sense when the feature is time, e.g. years and the main effect captures some seasonal effect.

% =============================================================================
% REmarks
% =============================================================================
The approach we take (functional decomposition) is flexible enough to adapt to different desideratea (e.g. favor different functional forms over others).
All the three measures would also work with any other decomposition like fANOVA or PDP.
It would even work with nonsensical decomposition, e.g.
true model for two featuresis $\fh(x) = x_1$, but we decompose as $f_{nonsense}(x) = x_1 + x_2 + Rest$ and we show plots of $x_1$ and $x_2$.
Complexity measure will not be so meaningful, but n.features would remain the same, and the R squared measure would be better for the first decomposition.
As such the measures (IA and C) are intertwined between the model and the decomposition we choose, which makes sense.
Problem with surrogate model: might approximate well, but not perfectly describe the model behaviour.
e.g. x1, x2 strongly correlated, black box uses only x1.
surrogate model uses x2.
then perfect fidelity, but not true effects.
All three measures would also work with surrogate models, because we can show how big their $R^2$ is for predicting the black box predictions and we can measure the complexity of the surrogate by using it's own C.
For n.features we have now two options: we could use number of features in black box model or number of features in the surrogate model.
What if the decomposition is bad?
Well, for ALE we can show that it's a desirable decomposition.
But for any other, the $R^2$ will be very bad if the approximation is unfaithful.

% =============================================================================
% Further research to build on top
% =============================================================================
Instead of looking at the proposed measure, the view of a machine learning model through the lens of functional decomposition, it is possible to propose more measures:
For example a measure that only checks whether the main effects are linear.
Or a measure for the monotonicity of the main effects that detects whether a function is monotonuous or not.
Or a measure that differently weights the interaction based on the depth:
Two-way interactions might be okay, but everything with higher-order is penalized.

This measure also enhances ALE plots even when not used to measure model.
For cheap cost, because we might already have ALE plots.
For example we can compute Average Marginal Effects from the approximation and report those.
We can sort ALE plots by complexity c and show the ones with similar complexity ("first row shows the plots with linear relationships, second with complexity of two, ...").
With the feature.used approach we can omit computation of ALE plots of features that are not used.

% =============================================================================
% Implementation Note
% =============================================================================
The source code is available along with the paper on Github: LINK.
The measure are implemented in the iml package \citep{iml2018} which is available on CRAN.
All examples are done with mlr package \citep{JMLR:v17:15-066} in R \citep{r2016}.



% =============================================================================
% Funding
% =============================================================================
This work is funded by the Bavarian State Ministry of Science and the Arts in the framework of the Centre Digitisation.Bavaria (ZD.B)




% =============================================================================
% Further chapter material
% =============================================================================


%Problems:
%- For tree based methods and other models with step curves, the ale fanova decomp never goes to perfectly zero, because it interpolates a little bit between the steps.
%When true marginal function is step function, then it adds to the SSE unecessarily
%- Unclear how many intervals
%- Weighted by data sensity (can be unintuitive when looking at plot) or all plot point same weight (probably very wrong). Solution: Make clear in ALE plot where most data is with rug or alpha.
