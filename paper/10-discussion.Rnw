\Sexpr{set_parent('paper.Rnw')}
\section{Discussion}
\label{sec:discussion}


% =============================================================================
% Results summary
% =============================================================================
We proposed three model-agnostic measures of the functional complexity of a machine learning model: a heuristic for numbers of features used, the average main effect complexity, and the interaction strength.
All of those measures were motivated by the functional decomposition of the model prediction function and we demonstrated their usefulness in various examples.
As these measures are model-agnostic, one application of these measure is the comparison of interpretability across different model classes and even within a certain model class when different configurations / hyperparameter settings strongly affect the model structure (e.g. adding interactions into linear models or changing the kernel in a support vector machine).
The measures can be directly optimized in a multi-objective optimization setting.
It also allows to tune complete pipeline with feature selection \citep{guyon2003introduction} to improve interpetability

% =============================================================================
% Limitations
% =============================================================================
The measures as we proposed the come with a few limitations.
The measures favor sparse linear models without interaction terms.
In the end, will a user also find models that minimize our notions of complexity more useful?
We did not test whether optimizing those measures improves the interpretability of the models for humans, which ideally should be tested in a user-survey.
This was outside of the scope of our research.
These complexity measures can be directly used in research settings with user-surveys and correlated with user-reported outcomes and measure of how fast users where to grasp a model.
As \citep{rudin2018please} argues, the interpretability depends on the application and the audience and the preferred tradeoff between performance, sparsity, additivity and interactions might vary between different appication and audience.
We believe our measures are useful for user surveys, because these measures can always be computed for the models that are being compared and correlated with user feedback to see what the tradeoff between performance and the different dimensions of complexity are in this particular case.


% =============================================================================
% Areas to improve
% =============================================================================
The proposed measure for the main effect complexity could be improved by considering shapes different from linear segments.
For example quadratic components or seasonal components, which make sense when the feature is time, e.g. years and the main effect captures some seasonal effect.


% =============================================================================
% Further research to build on top
% =============================================================================
Instead of looking at the proposed measure, the view of a machine learning model through the lens of functional decomposition, it is possible to propose more measures:
For example a measure that only checks whether the main effects are linear.
Or a measure for the monotonicity of the main effects that detects whether a function is monotonuous or not.
Or a measure that differently weights the interaction based on the depth:
Two-way interactions might be okay, but everything with higher-order is penalized.

This measure also enhances ALE plots even when not used to measure model.
For cheap cost, because we might already have ALE plots.
For example we can compute Average Marginal Effects from the approximation and report those.
We can sort ALE plots by complexity c and show the ones with similar complexity ("first row shows the plots with linear relationships, second with complexity of two, ...").
With the feature.used approach we can omit computation of ALE plots of features that are not used.

% =============================================================================
% Implementation Note
% =============================================================================
The measure are implemented in the iml package \citep{iml2018} which is available on CRAN.



% =============================================================================
% Funding
% =============================================================================
This work is funded by the Bavarian State Ministry of Science and the Arts in the framework of the Centre Digitisation.Bavaria (ZD.B)




% =============================================================================
% Further chapter material
% =============================================================================


%Problems:
%- For tree based methods and other models with step curves, the ale fanova decomp never goes to perfectly zero, because it interpolates a little bit between the steps.
%When true marginal function is step function, then it adds to the SSE unecessarily
%- Unclear how many intervals
%- Weighted by data sensity (can be unintuitive when looking at plot) or all plot point same weight (probably very wrong). Solution: Make clear in ALE plot where most data is with rug or alpha.
