\Sexpr{set_parent('paper.Rnw')}
\section{Discussion}
\label{sec:discussion}


% =============================================================================
% Key findings
% =============================================================================
We proposed three model-agnostic measures for machine learning model complexity based on functional decomposition: number of features used, interaction strength and main effect complexity.
Due to their model-agnostic nature, the measures allow model comparison across different model classes.
We argued that minimizing these measures for a machine learning model improves its post-hoc interpretation.
We demonstrated that the measures can be optimized directly with multi-objective optimization to make the trade-off between interpretability and performance explicit, which helps in model selection.
Our proposed measures can be applied to many model since they are model-agnostic, work for regression and binary classification (based on probabilities).
We formulated the measures with both continuous and categorical features in mind, but leave an in-depth investigation of categorical features open for future work.
They can be used for model selection, but also in benchmarks for comparing model classes.


% =============================================================================
% Limitations
% =============================================================================
\subsubsection{Limitations.}
The proposed decomposition of the prediction function and definition of the complexity measures will not be appropriate in every situation.
For example, all higher order effects are combined into a single interaction strength measure that does not distinguish between two-way interactions and higher order interactions.
Two models can have the same IAS, but one has a  single two-way interaction, the other many different higher order interactions.
However, the framework of ALE decomposition allows to estimate higher order effects and to construct different interaction measures.
The main effect complexity measure only considers linear segments but not e.g. seasonal components or other structures.
Furthermore, the complexity measures quantify machine learning models from a functional point of view and ignore the structure of the model (e.g. whether it can be represented by a tree).
% =============================================================================
% What's next
% =============================================================================
\subsubsection{The bigger picture.}
Interpretability is a high-dimensional concept (sparsity, additivity, fidelity, human simulability, ...) and we need several approaches to make interpretability measurable.
In this context we see our work complementary to other approaches \citep{friedler2019assessing,dhurandhar2017tip,plumb2019regularizing}, which together form a basis for a more rigorous definition of interpretability as called by \citep{doshi2017towards,Lipton2016}.
Availability of different interpretability measures also fits in with the notion that interpretability depends on the audience and the context \citep{rudin2018please}.
Different situations require differently weighted interpretability measures.
In some situations we might prefer sparseness and a lack of interactions, in other it's important that we can represent the model as a decision list.
A multi-dimensional view of interpretability solves the lack of definition of interpretability and supports researcher to make quantified, verifiable and clearer statements about interpretability.

% =============================================================================
% Implementation Note
% =============================================================================
\subsubsection{Implementation.}
The paper and code of the experiments is available on Github: \url{https://github.com/compstat-lmu/paper_2018_autoiml}.
All examples are done with mlr package \citep{JMLR:v17:15-066} in R \citep{r2018}.
% =============================================================================
% Funding
% =============================================================================
\subsubsection{Funding.}
This work is funded by the Bavarian State Ministry of Science and the Arts in the framework of the Centre Digitisation.Bavaria (ZD.B) and supported by the German Federal Ministry of Education and Research (BMBF) under Grant No. 01IS18036A.
The authors of this work take full responsibilities for its content.


% =============================================================================
% =============================================================================
% Further material
% =============================================================================
% =============================================================================

% =============================================================================
% REmarks
% =============================================================================
% The approach we take (functional decomposition) is flexible enough to adapt to different desideratea (e.g. favor different functional forms over others).
% All the three measures would also work with any other decomposition like fANOVA or PDP.
% It would even work with nonsensical decomposition, e.g.
% true model for two featuresis $\fh(x) = x_1$, but we decompose as $f_{nonsense}(x) = x_1 + x_2 + Rest$ and we show plots of $x_1$ and $x_2$.
% Complexity measure will not be so meaningful, but n.features would remain the same, and the R squared measure would be better for the first decomposition.
% As such the measures (IA and C) are intertwined between the model and the decomposition we choose, which makes sense.
% Problem with surrogate model: might approximate well, but not perfectly describe the model behaviour.
% e.g. x1, x2 strongly correlated, black box uses only x1.
% surrogate model uses x2.
% then perfect fidelity, but not true effects.
% All three measures would also work with surrogate models, because we can show how big their $R^2$ is for predicting the black box predictions and we can measure the complexity of the surrogate by using it's own C.
% For n.features we have now two options: we could use number of features in black box model or number of features in the surrogate model.
% What if the decomposition is bad?
% Well, for ALE we can show that it's a desirable decomposition.
% But for any other, the $R^2$ will be very bad if the approximation is unfaithful.

% =============================================================================
% Areas to improve
% =============================================================================
% The proposed measure for the main effect complexity could be improved by considering shapes different from linear segments.
% For example quadratic components or seasonal components, which make sense when the feature is time, e.g. years and the main effect captures some seasonal effect.

%Problems:
%- Unclear how many intervals
%- Weighted by data sensity (can be unintuitive when looking at plot) or all plot point same weight (probably very wrong). Solution: Make clear in ALE plot where most data is with rug or alpha.
